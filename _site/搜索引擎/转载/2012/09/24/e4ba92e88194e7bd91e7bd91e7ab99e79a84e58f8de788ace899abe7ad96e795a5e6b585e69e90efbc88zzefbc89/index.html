
<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7 ie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8 ie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9 ie" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1">
	<title>互联网网站的反爬虫策略浅析（zz）</title>
	<meta name="author" content="codeboy">
	<link href='/assets/themes/the-program/css/style.css' rel="stylesheet" media="all">
	<!-- <link href="http://feeds.feedburner.com/" rel="alternate" title="互联网网站的反爬虫策略浅析（zz）" type="application/atom+xml"> -->
	<!-- <script src="http://cdnjs.cloudflare.com/ajax/libs/modernizr/2.0.6/modernizr.min.js"></script> -->
</head>
<body>

<div id="page" class="hentry">
	<header class="the-header">
		<div class="unit-head">
			<div class="unit-inner unit-head-inner">
				<nav class="nav-global">
					<ul>
						<li class="logo"><a href="/">codeboy</a></li>
						<li class="archive"><a href="/archive.html">文章</a></li>
						<li class="page"><a href="/pages.html">页面</a></li>
						<li class="category"><a href="/categories.html">分类</a></li>
						<li class="tag"><a href="/tags.html">标签</a></li>
						<li class="about_me"><a href="/about.html">关于我</a></li>
						<!-- <li class="forkme"><div><iframe src="http://markdotto.github.com/github&#45;buttons/github&#45;btn.html?user=plusjade&#38;repo=jekyll&#45;bootstrap&#38;type=fork&#38;count=true" -->
						<!-- 			allowtransparency="true" frameborder="0" scrolling="0" width="95px" height="20px"></iframe></div></li> -->
					</ul>
				</nav>
			</div><!-- unit-inner -->
		</div><!-- unit-head -->
	</header>
	<div class="body" role="main">
		<div class="unit-body">
			<div class="unit-inner unit-body-inner">
				<div class="entry-content">
					
<article class="unit-article layout-post">
	<div class="unit-inner unit-article-inner">
		<div class="content">
			<header>
				<div class="unit-head">
					<div class="unit-inner unit-head-inner">
						<h1 class="h2 entry-title">互联网网站的反爬虫策略浅析（zz）</h1>
					</div><!-- unit-inner -->
				</div><!-- unit-head -->
			</header>

			<div class="bd">
				<div class="entry-content">
					<div>因为搜索引擎的流行，网络爬虫已经成了很普及网络技术，除了专门做搜索的Google，Yahoo，微软，百度以外，几乎每个大型门户网站都有自己的搜索引擎，大大小小叫得出来名字得就几十种，还有各种不知名的几千几万种，对于一个内容型驱动的网站来说，受到网络爬虫的光顾是不可避免的。</div>
<div id="blog_content">一些智能的搜索引擎爬虫的爬取频率比较合理，对网站资源消耗比较少，但是很多糟糕的网络爬虫，对网页爬取能力很差，经常并发几十上百个请求循环重复抓取，这种爬虫对中小型网站往往是毁灭性打击，特别是一些缺乏爬虫编写经验的程序员写出来的爬虫破坏力极强。曾经有一次我在<a href="http://www.iteye.com/" target="_blank">JavaEye</a>的日志里面发现一个User-Agent是Java的爬虫一天之内爬取了将近100万次动态请求。这是一个用JDK标准类库编写的简单爬取网页程序，由于JavaEye网站内部链接构成了回环导致程序陷入了死循环。对于JavaEye这种百万PV级别的网站来说，这种爬虫造成的访问压力会非常大，会导致网站访问速度缓慢，甚至无法访问。此外，相当数量的的网页爬虫目的是盗取目标网站的内容。比方说JavaEye网站就曾经被两个竞争对手网站爬取论坛帖子，然后在自己的论坛里面用机器人发帖，因此这种爬虫不仅仅影响网站访问速度，而且侵犯了网站的版权。

对于一个原创内容丰富，URL结构合理易于爬取的网站来说，简直就是各种爬虫的盘中大餐，很多网站的访问流量构成当中，爬虫带来的流量要远远超过真实用户访问流量，甚至爬虫流量要高出真实流量一个数量级。像JavaEye网站虽然设置了相当严格的反爬虫策略，但是网站处理的动态请求数量仍然是真实用户访问流量的2倍。可以肯定的说，当今互联网的网络流量至少有2/3的流量爬虫带来的。因此反爬虫是一个值得网站长期探索和解决的问题。

<!--more-->

一、手工识别和拒绝爬虫的访问

有相当多的爬虫对网站会造成非常高的负载，因此识别爬虫的来源IP是很容易的事情。最简单的办法就是用netstat检查80端口的连接：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=netstat%20-nt%20%7C%20grep%20youhostip%3A80%20%7C%20awk%20'%7Bprint%20%245%7D'%20%7C%20awk%20-F%22%3A%22%20'%7Bprint%20%241%7D'%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=netstat%20-nt%20%7C%20grep%20youhostip%3A80%20%7C%20awk%20'%7Bprint%20%245%7D'%20%7C%20awk%20-F%22%3A%22%20'%7Bprint%20%241%7D'%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>netstat -nt | grep youhostip:80 | awk '{print $5}' | awk -F":" '{print $1}'| sort | uniq -c | sort -r -n</li>
</ol>
</div>
这行shell可以按照80端口连接数量对来源IP进行排序，这样可以直观的判断出来网页爬虫。一般来说爬虫的并发连接非常高。

如果使用lighttpd做Web Server，那么就更简单了。lighttpd的mod_status提供了非常直观的并发连接的信息，包括每个连接的来源IP，访问的URL，连接状态和连接时间等信息，只要检查那些处于handle-request状态的高并发IP就可以很快确定爬虫的来源IP了。

拒绝爬虫请求既可以通过内核防火墙来拒绝，也可以在web server拒绝，比方说用iptables拒绝：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=iptables%20-A%20INPUT%20-i%20eth0%20-j%20DROP%20-p%20tcp%20--dport%2080%20-s%2084.80.46.0%2F24%20%20" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=iptables%20-A%20INPUT%20-i%20eth0%20-j%20DROP%20-p%20tcp%20--dport%2080%20-s%2084.80.46.0%2F24%20%20" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>iptables -A INPUT -i eth0 -j DROP -p tcp --dport 80 -s 84.80.46.0/24</li>
</ol>
</div>
直接封锁爬虫所在的C网段地址。这是因为一般爬虫都是运行在托管机房里面，可能在一个C段里面的多台服务器上面都有爬虫，而这个C段不可能是用户宽带上网，封锁C段可以很大程度上解决问题。

有些人提出一种脑残的观点，说我要惩罚这些爬虫。我专门在网页里面设计动态循环链接页面，让爬虫掉进陷阱，死循环爬不出来，其实根本用不着设置陷阱，弱智爬虫对正常网页自己就爬不出来，这样做多此一举不说，而且会让真正的搜索引擎降低你的网页排名。而且运行一个爬虫根本不消耗什么机器资源，相反，真正宝贵的是你的服务器CPU资源和服务器带宽，简单的拒绝掉爬虫的请求是反爬虫最有效的策略。

二、通过识别爬虫的User-Agent信息来拒绝爬虫

有很多爬虫并不会以很高的并发连接爬取，一般不容易暴露自己；有些爬虫的来源IP分布很广，很难简单的通过封锁IP段地址来解决问题；另外还有很多各种各样的小爬虫，它们在尝试Google以外创新的搜索方式，每个爬虫每天爬取几万的网页，几十个爬虫加起来每天就能消耗掉上百万动态请求的资源，由于每个小爬虫单独的爬取量都很低，所以你很难把它从每天海量的访问IP地址当中把它准确的挖出来。

这种情况下我们可以通过爬虫的User-Agent信息来识别。每个爬虫在爬取网页的时候，会声明自己的User-Agent信息，因此我们就可以通过记录和分析User-Agent信息来挖掘和封锁爬虫。我们需要记录每个请求的User-Agent信息，对于Rails来说我们可以简单的在app/controllers/application.rb里面添加一个全局的before_filter，来记录每个请求的User-Agent信息：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=logger.info%20%22HTTP_USER_AGENT%20%23%7Brequest.env%5B%22HTTP_USER_AGENT%22%5D%7D%22%20%20" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=logger.info%20%22HTTP_USER_AGENT%20%23%7Brequest.env%5B%22HTTP_USER_AGENT%22%5D%7D%22%20%20" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>logger.info "HTTP_USER_AGENT #{request.env["HTTP_USER_AGENT"]}"</li>
</ol>
</div>
然后统计每天的production.log，抽取User-Agent信息，找出访问量最大的那些User-Agent。要注意的是我们只关注那些爬虫的User-Agent信息，而不是真正浏览器User-Agent，所以还要排除掉浏览器User-Agent，要做到这一点仅仅需要一行shell：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=grep%20HTTP_USER_AGENT%20production.log%20%7C%20grep%20-v%20-E%20'MSIE%7CFirefox%7CChrome%7COpera%7CSafari%7CGecko'%20%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20%7C%20head%20-n%20100%20%3E%20bot.log%20%20" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=grep%20HTTP_USER_AGENT%20production.log%20%7C%20grep%20-v%20-E%20'MSIE%7CFirefox%7CChrome%7COpera%7CSafari%7CGecko'%20%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20%7C%20head%20-n%20100%20%3E%20bot.log%20%20" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>grep HTTP_USER_AGENT production.log | grep -v -E 'MSIE|Firefox|Chrome|Opera|Safari|Gecko' | sort | uniq -c | sort -r -n | head -n 100 &gt; bot.log</li>
</ol>
</div>
统计结果类似这样：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=%20%2057335%20HTTP_USER_AGENT%20Baiduspider%2B(%2Bhttp%3A%2F%2Fwww.baidu.com%2Fsearch%2Fspider.htm)%0A%20%2056639%20HTTP_USER_AGENT%20Mozilla%2F5.0%20(compatible%3B%20Googlebot%2F2.1%3B%20%2Bhttp%3A%2F%2Fwww.google.com%2Fbot.html)%0A%20%2042610%20HTTP_USER_AGENT%20Mediapartners-Google%0A%20%2019131%20HTTP_USER_AGENT%20msnbot%2F2.0b%20(%2Bhttp%3A%2F%2Fsearch.msn.com%2Fmsnbot.htm)" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=%20%2057335%20HTTP_USER_AGENT%20Baiduspider%2B(%2Bhttp%3A%2F%2Fwww.baidu.com%2Fsearch%2Fspider.htm)%0A%20%2056639%20HTTP_USER_AGENT%20Mozilla%2F5.0%20(compatible%3B%20Googlebot%2F2.1%3B%20%2Bhttp%3A%2F%2Fwww.google.com%2Fbot.html)%0A%20%2042610%20HTTP_USER_AGENT%20Mediapartners-Google%0A%20%2019131%20HTTP_USER_AGENT%20msnbot%2F2.0b%20(%2Bhttp%3A%2F%2Fsearch.msn.com%2Fmsnbot.htm)" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>57335 HTTP_USER_AGENT Baiduspider+(+http://www.baidu.com/search/spider.htm)</li>
	<li>56639 HTTP_USER_AGENT Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)</li>
	<li>42610 HTTP_USER_AGENT Mediapartners-Google</li>
	<li>19131 HTTP_USER_AGENT msnbot/2.0b (+http://search.msn.com/msnbot.htm)</li>
</ol>
</div>
从日志就可以直观的看出每个爬虫的请求次数。要根据User-Agent信息来封锁爬虫是件很容易的事情，lighttpd配置如下：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=%24HTTP%5B%22useragent%22%5D%20%3D~%20%22qihoobot%7C%5EJava%7CCommons-HttpClient%7CWget%7C%5EPHP%7CRuby%7CPython%22%20%7B%0A%20%20url.rewrite%20%3D%20(%20%22%5E%2F(.*)%22%20%3D%3E%20%22%2Fcrawler.html%22%20)%0A%7D" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=%24HTTP%5B%22useragent%22%5D%20%3D~%20%22qihoobot%7C%5EJava%7CCommons-HttpClient%7CWget%7C%5EPHP%7CRuby%7CPython%22%20%7B%0A%20%20url.rewrite%20%3D%20(%20%22%5E%2F(.*)%22%20%3D%3E%20%22%2Fcrawler.html%22%20)%0A%7D" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>$HTTP["useragent"] =~ "qihoobot|^Java|Commons-HttpClient|Wget|^PHP|Ruby|Python" {</li>
	<li>  url.rewrite = ( "^/(.*)" =&gt; "/crawler.html" )</li>
	<li>}</li>
</ol>
</div>
使用这种方式来封锁爬虫虽然简单但是非常有效，除了封锁特定的爬虫，还可以封锁常用的编程语言和HTTP类库的User-Agent信息，这样就可以避免很多无谓的程序员用来练手的爬虫程序对网站的骚扰。

还有一种比较常见的情况，就是某个搜索引擎的爬虫对网站爬取频率过高，但是搜索引擎给网站带来了很多流量，我们并不希望简单的封锁爬虫，仅仅是<a href="http://blog.lighttpd.net/articles/2008/08/22/delay-request-handling-for-stupid-crawlers" target="_blank">希望降低爬虫的请求频率，减轻爬虫对网站造成的负载</a>，那么我们可以这样做：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=%24HTTP%5B%22user-agent%22%5D%20%3D~%20%22Baiduspider%2B%22%20%7B%0A%20%20%20%20connection.delay-seconds%20%3D%2010%0A%7D" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=%24HTTP%5B%22user-agent%22%5D%20%3D~%20%22Baiduspider%2B%22%20%7B%0A%20%20%20%20connection.delay-seconds%20%3D%2010%0A%7D" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>$HTTP["user-agent"] =~ "Baiduspider+" {</li>
	<li>    connection.delay-seconds = 10</li>
	<li>}</li>
</ol>
</div>
对百度的爬虫请求延迟10秒钟再进行处理，这样就可以有效降低爬虫对网站的负载了。

三、通过网站流量统计系统和日志分析来识别爬虫

有些爬虫喜欢修改User-Agent信息来伪装自己，把自己伪装成一个真实浏览器的User-Agent信息，让你无法有效的识别。这种情况下我们可以通过网站流量系统记录的真实用户访问IP来进行识别。

主流的网站流量统计系统不外乎两种实现策略：一种策略是在网页里面嵌入一段js，这段js会向特定的统计服务器发送请求的方式记录访问量；另一种策略是直接分析服务器日志，来统计网站访问量。在理想的情况下，嵌入js的方式统计的网站流量应该高于分析服务器日志，这是因为用户浏览器会有缓存，不一定每次真实用户访问都会触发服务器的处理。但实际情况是，分析服务器日志得到的网站访问量远远高于嵌入js方式，极端情况下，甚至要高出10倍以上。

现在很多网站喜欢采用awstats来分析服务器日志，来计算网站的访问量，但是当他们一旦采用Google Analytics来统计网站流量的时候，却发现GA统计的流量远远低于awstats，为什么GA和awstats统计会有这么大差异呢？罪魁祸首就是把自己伪装成浏览器的网络爬虫。这种情况下awstats无法有效的识别了，所以awstats的统计数据会虚高。

其实作为一个网站来说，如果希望了解自己的网站真实访问量，希望精确了解网站每个频道的访问量和访问用户，应该用页面里面嵌入js的方式来开发自己的网站流量统计系统。自己做一个网站流量统计系统是件很简单的事情，写段服务器程序响应客户段js的请求，分析和识别请求然后写日志的同时做后台的异步统计就搞定了。

通过流量统计系统得到的用户IP基本是真实的用户访问，因为一般情况下爬虫是无法执行网页里面的js代码片段的。所以我们可以拿流量统计系统记录的IP和服务器程序日志记录的IP地址进行比较，如果服务器日志里面某个IP发起了大量的请求，在流量统计系统里面却根本找不到，或者即使找得到，可访问量却只有寥寥几个，那么无疑就是一个网络爬虫。

分析服务器日志统计访问最多的IP地址段一行shell就可以了：
<div id="">
<div>
<div>C代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=grep%20Processing%20production.log%20%7C%20awk%20'%7Bprint%20%244%7D'%20%7C%20awk%20-F'.'%20'%7Bprint%20%241%22.%22%242%22.%22%243%22.0%22%7D'%20%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20%7C%20head%20-n%20200%20%3E%20stat_ip.log%20%20" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=grep%20Processing%20production.log%20%7C%20awk%20'%7Bprint%20%244%7D'%20%7C%20awk%20-F'.'%20'%7Bprint%20%241%22.%22%242%22.%22%243%22.0%22%7D'%20%7C%20sort%20%7C%20uniq%20-c%20%7C%20sort%20-r%20-n%20%7C%20head%20-n%20200%20%3E%20stat_ip.log%20%20" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>grep Processing production.log | awk '{print $4}' | awk -F'.' '{print $1"."$2"."$3".0"}' | sort | uniq -c | sort -r -n | head -n 200 &gt; stat_ip.log</li>
</ol>
</div>
然后把统计结果和流量统计系统记录的IP地址进行对比，排除真实用户访问IP，再排除我们希望放行的网页爬虫，比方Google，百度，微软msn爬虫等等。最后的分析结果就就得到了爬虫的IP地址了。以下代码段是个简单的实现示意：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=whitelist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flib%2Fwhitelist.txt%22)%20%7B%20%7Cline%7C%20whitelist%20%3C%3C%20line.split%5B0%5D.strip%20if%20line%20%7D%0A%0Arealiplist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flog%2Fvisit_ip.log%22)%20%7B%20%7Cline%7C%20%20realiplist%20%3C%3C%20line.strip%20if%20line%20%7D%0A%0Aiplist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flog%2Fstat_ip.log%22)%20do%20%7Cline%7C%0A%20%20ip%20%3D%20line.split%5B1%5D.strip%0A%20%20iplist%20%3C%3C%20ip%20if%20line.split%5B0%5D.to_i%20%3E%203000%20%26%26%20!whitelist.include%3F(ip)%20%26%26%20!realiplist.include%3F(ip)%0Aend%20%0A%0AReport.deliver_crawler(iplist)" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=whitelist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flib%2Fwhitelist.txt%22)%20%7B%20%7Cline%7C%20whitelist%20%3C%3C%20line.split%5B0%5D.strip%20if%20line%20%7D%0A%0Arealiplist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flog%2Fvisit_ip.log%22)%20%7B%20%7Cline%7C%20%20realiplist%20%3C%3C%20line.strip%20if%20line%20%7D%0A%0Aiplist%20%3D%20%5B%5D%0AIO.foreach(%22%23%7BRAILS_ROOT%7D%2Flog%2Fstat_ip.log%22)%20do%20%7Cline%7C%0A%20%20ip%20%3D%20line.split%5B1%5D.strip%0A%20%20iplist%20%3C%3C%20ip%20if%20line.split%5B0%5D.to_i%20%3E%203000%20%26%26%20!whitelist.include%3F(ip)%20%26%26%20!realiplist.include%3F(ip)%0Aend%20%0A%0AReport.deliver_crawler(iplist)" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>whitelist = []</li>
	<li>IO.foreach("#{RAILS_ROOT}/lib/whitelist.txt") { |line| whitelist &lt;&lt; line.split[0].strip if line }</li>
	<li></li>
	<li>realiplist = []</li>
	<li>IO.foreach("#{RAILS_ROOT}/log/visit_ip.log") { |line|  realiplist &lt;&lt; line.strip if line }</li>
	<li></li>
	<li>iplist = []</li>
	<li>IO.foreach("#{RAILS_ROOT}/log/stat_ip.log") do |line|</li>
	<li>  ip = line.split[1].strip</li>
	<li>  iplist &lt;&lt; ip if line.split[0].to_i &gt; 3000 &amp;&amp; !whitelist.include?(ip) &amp;&amp; !realiplist.include?(ip)</li>
	<li>end</li>
	<li></li>
	<li>Report.deliver_crawler(iplist)</li>
</ol>
</div>
分析服务器日志里面请求次数超过3000次的IP地址段，排除白名单地址和真实访问IP地址，最后得到的就是爬虫IP了，然后可以发送邮件通知管理员进行相应的处理。

四、网站的实时反爬虫防火墙实现策略

通过分析日志的方式来识别网页爬虫不是一个实时的反爬虫策略。如果一个爬虫非要针对你的网站进行处心积虑的爬取，那么他可能会采用分布式爬取策略，比方说寻找几百上千个国外的代理服务器疯狂的爬取你的网站，从而导致网站无法访问，那么你再分析日志是不可能及时解决问题的。所以必须采取实时反爬虫策略，要能够动态的实时识别和封锁爬虫的访问。

要自己编写一个这样的实时反爬虫系统其实也很简单。比方说我们可以用memcached来做访问计数器，记录每个IP的访问频度，在单位时间之内，如果访问频率超过一个阀值，我们就认为这个IP很可能有问题，那么我们就可以返回一个验证码页面，要求用户填写验证码。如果是爬虫的话，当然不可能填写验证码，所以就被拒掉了，这样很简单就解决了爬虫问题。

用memcache记录每个IP访问计数，单位时间内超过阀值就让用户填写验证码，用Rails编写的示例代码如下：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=ip_counter%20%3D%20Rails.cache.increment(request.remote_ip)%0Aif%20!ip_counter%0A%20%20Rails.cache.write(request.remote_ip%2C%201%2C%20%3Aexpires_in%20%3D%3E%2030.minutes)%0Aelsif%20ip_counter%20%3E%202000%0A%20%20render%20%3Atemplate%20%3D%3E%20'test'%2C%20%3Astatus%20%3D%3E%20401%20and%20return%20false%0Aend%0A" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=ip_counter%20%3D%20Rails.cache.increment(request.remote_ip)%0Aif%20!ip_counter%0A%20%20Rails.cache.write(request.remote_ip%2C%201%2C%20%3Aexpires_in%20%3D%3E%2030.minutes)%0Aelsif%20ip_counter%20%3E%202000%0A%20%20render%20%3Atemplate%20%3D%3E%20'test'%2C%20%3Astatus%20%3D%3E%20401%20and%20return%20false%0Aend%0A" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>ip_counter = Rails.cache.increment(request.remote_ip)</li>
	<li>if !ip_counter</li>
	<li>  Rails.cache.write(request.remote_ip, 1, :expires_in =&gt; 30.minutes)</li>
	<li>elsif ip_counter &gt; 2000</li>
	<li>  render :template =&gt; 'test', :status =&gt; 401 and return false</li>
	<li>end</li>
</ol>
</div>
这段程序只是最简单的示例，实际的代码实现我们还会添加很多判断，比方说我们可能要排除白名单IP地址段，要允许特定的User-Agent通过，要针对登录用户和非登录用户，针对有无referer地址采取不同的阀值和计数加速器等等。

此外如果分布式爬虫爬取频率过高的话，过期就允许爬虫再次访问还是会对服务器造成很大的压力，因此我们可以添加一条策略：针对要求用户填写验证码的IP地址，如果该IP地址短时间内继续不停的请求，则判断为爬虫，加入黑名单，后续请求全部拒绝掉。为此，示例代码可以改进一下：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=before_filter%20%3Aip_firewall%2C%20%3Aexcept%20%3D%3E%20%3Atest%0Adef%20ip_firewall%0A%20%20render%20%3Afile%20%3D%3E%20%22%23%7BRAILS_ROOT%7D%2Fpublic%2F403.html%22%2C%20%3Astatus%20%3D%3E%20403%20if%20BlackList.include%3F(ip_sec)%0Aend" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=before_filter%20%3Aip_firewall%2C%20%3Aexcept%20%3D%3E%20%3Atest%0Adef%20ip_firewall%0A%20%20render%20%3Afile%20%3D%3E%20%22%23%7BRAILS_ROOT%7D%2Fpublic%2F403.html%22%2C%20%3Astatus%20%3D%3E%20403%20if%20BlackList.include%3F(ip_sec)%0Aend" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>before_filter :ip_firewall, :except =&gt; :test</li>
	<li>def ip_firewall</li>
	<li>  render :file =&gt; "#{RAILS_ROOT}/public/403.html", :status =&gt; 403 if BlackList.include?(ip_sec)</li>
	<li>end</li>
</ol>
</div>
我们可以定义一个全局的过滤器，对所有请求进行过滤，出现在黑名单的IP地址一律拒绝。对非黑名单的IP地址再进行计数和统计：
<div id="">
<div>
<div>Ruby代码 <object width="14" height="15" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" /><param name="wmode" value="transparent" /><param name="flashvars" value="clipboard=ip_counter%20%3D%20Rails.cache.increment(request.remote_ip)%0Aif%20!ip_counter%0A%20%20Rails.cache.write(request.remote_ip%2C%201%2C%20%3Aexpires_in%20%3D%3E%2030.minutes)%0Aelsif%20ip_counter%20%3E%202000%0A%20%20crawler_counter%20%3D%20Rails.cache.increment(%22crawler%2F%23%7Brequest.remote_ip%7D%22)%0A%20%20if%20!crawler_counter%0A%20%20%20%20Rails.cache.write(%22crawler%2F%23%7Brequest.remote_ip%7D%22%2C%201%2C%20%3Aexpires_in%20%3D%3E%2010.minutes)%0A%20%20elsif%20crawler_counter%20%3E%2050%0A%20%20%20%20BlackList.add(ip_sec)%0A%20%20%20%20render%20%3Afile%20%3D%3E%20%22%23%7BRAILS_ROOT%7D%2Fpublic%2F403.html%22%2C%20%3Astatus%20%3D%3E%20403%20and%20return%20false%0A%20%20end%0A%20%20render%20%3Atemplate%20%3D%3E%20'test'%2C%20%3Astatus%20%3D%3E%20401%20and%20return%20false%0Aend" /><param name="quality" value="high" /><param name="allowscriptaccess" value="always" /><param name="pluginspage" value="http://www.macromedia.com/go/getflashplayer" /><embed width="14" height="15" type="application/x-shockwave-flash" src="http://robbin.iteye.com/javascripts/syntaxhighlighter/clipboard_new.swf" wmode="transparent" flashvars="clipboard=ip_counter%20%3D%20Rails.cache.increment(request.remote_ip)%0Aif%20!ip_counter%0A%20%20Rails.cache.write(request.remote_ip%2C%201%2C%20%3Aexpires_in%20%3D%3E%2030.minutes)%0Aelsif%20ip_counter%20%3E%202000%0A%20%20crawler_counter%20%3D%20Rails.cache.increment(%22crawler%2F%23%7Brequest.remote_ip%7D%22)%0A%20%20if%20!crawler_counter%0A%20%20%20%20Rails.cache.write(%22crawler%2F%23%7Brequest.remote_ip%7D%22%2C%201%2C%20%3Aexpires_in%20%3D%3E%2010.minutes)%0A%20%20elsif%20crawler_counter%20%3E%2050%0A%20%20%20%20BlackList.add(ip_sec)%0A%20%20%20%20render%20%3Afile%20%3D%3E%20%22%23%7BRAILS_ROOT%7D%2Fpublic%2F403.html%22%2C%20%3Astatus%20%3D%3E%20403%20and%20return%20false%0A%20%20end%0A%20%20render%20%3Atemplate%20%3D%3E%20'test'%2C%20%3Astatus%20%3D%3E%20401%20and%20return%20false%0Aend" quality="high" allowscriptaccess="always" pluginspage="http://www.macromedia.com/go/getflashplayer" /></object> <a title="收藏这段代码" href="http://robbin.iteye.com/blog/451014"><img src="http://robbin.iteye.com/images/icon_star.png" alt="收藏代码" /></a></div>
</div>
<ol start="1">
	<li>ip_counter = Rails.cache.increment(request.remote_ip)</li>
	<li>if !ip_counter</li>
	<li>  Rails.cache.write(request.remote_ip, 1, :expires_in =&gt; 30.minutes)</li>
	<li>elsif ip_counter &gt; 2000</li>
	<li>  crawler_counter = Rails.cache.increment("crawler/#{request.remote_ip}")</li>
	<li>  if !crawler_counter</li>
	<li>    Rails.cache.write("crawler/#{request.remote_ip}", 1, :expires_in =&gt; 10.minutes)</li>
	<li>  elsif crawler_counter &gt; 50</li>
	<li>    BlackList.add(ip_sec)</li>
	<li>    render :file =&gt; "#{RAILS_ROOT}/public/403.html", :status =&gt; 403 and return false</li>
	<li>  end</li>
	<li>  render :template =&gt; 'test', :status =&gt; 401 and return false</li>
	<li>end</li>
</ol>
</div>
</div>
<div id="blog_content">如果某个IP地址单位时间内访问频率超过阀值，再增加一个计数器，跟踪他会不会立刻填写验证码，如果他不填写验证码，在短时间内还是高频率访问，就把这个IP地址段加入黑名单，除非用户填写验证码激活，否则所有请求全部拒绝。这样我们就可以通过在程序里面维护黑名单的方式来动态的跟踪爬虫的情况，甚至我们可以自己写个后台来手工管理黑名单列表，了解网站爬虫的情况。这个策略已经比较智能了，但是还不够好！我们还可以继续改进：

1、用网站流量统计系统来改进实时反爬虫系统

还记得吗？网站流量统计系统记录的IP地址是真实用户访问IP，所以我们在网站流量统计系统里面也去操作memcached，但是这次不是增加计数值，而是减少计数值。在网站流量统计系统里面每接收到一个IP请求，就相应的cache.decrement(key)。所以对于真实用户的IP来说，它的计数值总是加1然后就减1，不可能很高。这样我们就可以大大降低判断爬虫的阀值，可以更加快速准确的识别和拒绝掉爬虫。

2、用时间窗口来改进实时反爬虫系统

爬虫爬取网页的频率都是比较固定的，不像人去访问网页，中间的间隔时间比较无规则，所以我们可以给每个IP地址建立一个时间窗口，记录IP地址最近12次访问时间，每记录一次就滑动一次窗口，比较最近访问时间和当前时间，如果间隔时间很长判断不是爬虫，清除时间窗口，如果间隔不长，就回溯计算指定时间段的访问频率，如果访问频率超过阀值，就转向验证码页面让用户填写验证码。

最终这个实时反爬虫系统就相当完善了，它可以很快的识别并且自动封锁爬虫的访问，保护网站的正常访问。不过有些爬虫可能相当狡猾，它也许会通过大量的爬虫测试来试探出来你的访问阀值，以低于阀值的爬取速度抓取你的网页，因此我们还需要辅助第3种办法，用日志来做后期的分析和识别，就算爬虫爬的再慢，它累计一天的爬取量也会超过你的阀值被你日志分析程序识别出来。

总之我们综合运用上面的四种反爬虫策略，可以很大程度上缓解爬虫对网站造成的负面影响，保证网站的正常访问。

</div>
<div></div>
<div>原文链接<a href="http://robbin.iteye.com/blog/451014">http://robbin.iteye.com/blog/451014</a></div>
					<div class="meta">
						<p class="date-publish">
							Published: 
							<date class="date-pub" title="2012-09-24T13:55:32Z" datetime="2012-09-24T13:55:32Z" pubdate>
							<span class="month"><abbr>September</abbr></span>
							<span class="day">24</span>
							<span class="year">2012</span>
							</date>
						</p>
						<ul class="list-category list-linear">
							<li class="list-head">category: </li>
							
							


  
     
    	<li><a href="/categories.html#搜索引擎-ref">
    		搜索引擎 <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#转载-ref">
    		转载 <span>9</span>
    	</a></li>
    
  


						</ul>
						<ul class="list-tag list-linear">
							<li class="list-head">tags: </li>
							
							


  
    
  



						</ul>
					</div><!-- meta -->
				</div><!-- entry-content -->
				<div class="misc-content">
					<!-- <div class="social"> -->
					<!-- 	<ul class="list&#45;linear"> -->
					<!-- 		<li><div class="twitter&#45;tweet"><a href="https://twitter.com/share" class="twitter&#45;share&#45;button" data&#45;count="horizontal" data&#45;via="" data&#45;lang="en">Tweet</a></div></li> -->
					<!-- 		<li><div class="twitter&#45;follow"><a href="https://twitter.com/" class="twitter&#45;follow&#45;button" data&#45;show&#45;count="false" data&#45;lang="en"></a></div></li> -->
					<!-- 	</ul> -->
					<!-- </div> -->
					<div class="comment">
					


  <!-- Duoshuo Comment BEGIN -->
<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"codeboyname"};
(function() {
 var ds = document.createElement('script');
 ds.type = 'text/javascript';ds.async = true;
 ds.src = 'http://static.duoshuo.com/embed.js';
 ds.charset = 'UTF-8';
 (document.getElementsByTagName('head')[0] 
  || document.getElementsByTagName('body')[0]).appendChild(ds);
 })();
</script>
<!-- Duoshuo Comment END -->





					</div>
				</div><!-- misc-content -->
			</div><!-- bd -->
			<footer class="unit-foot">
				<div class="unit-inner unit-foot-inner">
					<nav class="pagination">
						<ul>
							
							<li class="prev"><a class="internal" rel="prev"  href="/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/2012/09/20/e59ca8windowse4b88be4bdbfe794a8linuxe5b8b8e794a8e591bde4bba4" title="View 在windows下使用linux常用命令">&laquo; 在windows下使用linux常用命令</a></li>
							
							
							<li class="pipe"> | </li>
							
							
							<li class="next"><a class="internal" rel="next"  href="/%E5%BF%83%E6%83%85/2012/10/08/bug" title="View bug">bug &raquo;</a></li>
							
						</ul>
					</nav>
					<p class="gotop">
						<a href="#page">Back to Top</a>
					</p>
				</div>
			</footer>

		</div><!-- content -->
	</div><!-- unit-inner -->
</article>


				</div>
			</div><!-- unit-inner -->
		</div><!-- unit-body -->
	</div><!-- body -->
	<footer class="the-footer">
		<div class="unit-foot">
			<div class="unit-inner unit-foot-inner">
				<div class="misc vcard">
					<h4>about</h4>
					<ul>
						<!-- <li class="contact"><address><span class="author fn n">codeboy</span> &#45; <span class="fn email"></span></address></li> -->
						<li class="github"><a href="http://github.com/liwenxiang/" rel="me">github.com/liwenxiang</a></li>
						<!-- <li class="twitter"><a href="http://twitter.com//" rel="me">twitter.com/</a></li> -->
						<!-- <li class="rss"><a href="http://feeds.feedburner.com/">Subscribe to RSS Feed</a></li> -->
					</ul>
				</div><!-- misc -->
				<p class="licence">
					Theme: <a href="http://layouts-the.me">the_minimum</a> based on <a href="http://jekyllbootstrap.com/">Jekyll-bootstrap</a>.<br>
					Powered by <a href="https://github.com/mojombo/jekyll">Jekyll</a>.
				</p>
			</div><!-- unit-foot-inner -->
		</div><!-- unit-foot -->
	</footer>
</div><!-- page -->
<script>
	// (function(d, s) {
	// 	var js, fjs = d.getElementsByTagName(s)[0], load = function(url, id) {
	// 	if (d.getElementById(id)) {return;}
	// 	js = d.createElement(s); js.src = url; js.id = id;
	// 	fjs.parentNode.insertBefore(js, fjs);
	// 	};
	// load('//platform.twitter.com/widgets.js', 'tweetjs');
	// load('https://apis.google.com/js/plusone.js', 'gplus1js'); // Checkout http://j.mp/ApDgMr for usage html for this is <div class="g-plusone" data-size="medium"></div>
	// load('//connect.facebook.net/en_US/all.js#xfbml=1', 'fbjssdk'); // Checkout http://j.mp/wZw2xR for using open graph protorol html for this is <div class="fb-like" data-href="/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/%E8%BD%AC%E8%BD%BD/2012/09/24/e4ba92e88194e7bd91e7bd91e7ab99e79a84e58f8de788ace899abe7ad96e795a5e6b585e69e90efbc88zzefbc89" data-send="false" data-layout="button_count" data-width="450" data-show-faces="false" data-font="verdana"></div>
	}(document, 'script'));
</script>
<script>
/*! A fix for the iOS orientationchange zoom bug.Script by @scottjehl, rebound by @wilto. MIT License.*/
(function(j){var i=j.document;if(!i.querySelectorAll){return}var l=i.querySelectorAll("meta[name=viewport]")[0],a=l&&l.getAttribute("content"),h=a+", maximum-scale=1.0",d=a+", maximum-scale=10.0",g=true,c=j.orientation,k=0;if(!l){return}function f(){l.setAttribute("content",d);g=true}function b(){l.setAttribute("content",h);g=false}function e(m){c=Math.abs(j.orientation);k=Math.abs(m.gamma);if(k>8&&c===0){if(g){b()}}else{if(!g){f()}}}j.addEventListener("orientationchange",f,false);j.addEventListener("deviceorientation",e,false)})(this);
</script>
  
  
</body>
</html>

